{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2970632a-b7bb-4db7-84a3-8f384b14bc2d",
   "metadata": {},
   "source": [
    "### CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a9e58-6aa8-4241-b7c6-510c7f270f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1535ec-07ac-4490-9f43-b7835060ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"PATH TO SRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b594772-c1c9-4982-ad79-6995bd327fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import xarray as xr\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728d042-aecf-4d61-8fab-c2c7b45ed8a7",
   "metadata": {},
   "source": [
    "#### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2088fd4-3cae-4d92-9647-3eb1a30f3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_video = \"PATH TO VIDEOS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63b5df-fbda-4b36-8b7b-c95a9f928560",
   "metadata": {},
   "source": [
    "#### Loading and labeling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3829339-cd41-4663-82c2-8230a9f83dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.video_processing import extract_video_frames, label_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d7126-f3a4-4f0b-8fc5-bc339fa0487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = extract_video_frames(path_to_video)\n",
    "\n",
    "n_frames, H, W, d = frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c753d7-67b2-48d8-8b8f-63b768e17b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 500 random frames\n",
    "training_frames = np.random.choice(\n",
    "    np.arange(3000, 6000, dtype=int), size=500, replace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd061f-b2a8-4725-b04a-57181054aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i, idx_ in enumerate(training_frames):\n",
    "    print(f\"Frame ({i + 1}/{len(training_frames)})\")\n",
    "    labels += [label_frames(frames, idx_)]\n",
    "    clear_output(wait=True)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd668b0-2c7a-4774-a5f6-ab0f59d9f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = xr.DataArray(\n",
    "    frames[training_frames],\n",
    "    dims=(\"frames\", \"height\", \"width\", \"depth\"),\n",
    "    coords={\"frames\": labels},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f93ba-4498-434b-86f2-51254815812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "text = [\"No rat\", \"Rat\", \"Rai in the box\"]\n",
    "\n",
    "pos = 1\n",
    "for i in range(3):\n",
    "\n",
    "    plot_frames = training_dataset.sel(frames=i)[:10]\n",
    "\n",
    "    for f in range(10):\n",
    "        plt.subplot(3, 10, pos)\n",
    "        img = Image.fromarray(plot_frames[f].data)\n",
    "        plt.imshow(torchvision.transforms.Resize((300, 300))(img))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        if f == 0:\n",
    "            plt.ylabel(text[i])\n",
    "        pos = pos + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc984fe2-d316-400e-a27d-da618c8d843a",
   "metadata": {},
   "source": [
    "#### Organize training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9751a-e6be-4543-9581-7572aa3dc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.utils import apply_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b826a-3187-4f75-a141-154c543372e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = xr.load_dataarray(\"/home/projeto_mimi/dataset/training_dataset.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5398d-288b-45cb-a374-b268226de610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "trfs = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.7),\n",
    "        transforms.GaussianBlur((3, 3), sigma=(1, 2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((300, 300)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a45ae9-c176-4821-b3a3-182d1de54dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs and labels\n",
    "X, y = apply_transforms(\n",
    "    training_dataset, fraction=None, trfs=transforms.Resize((300, 300)), verbose=True\n",
    ")\n",
    "# Augment dataset\n",
    "X_aug, y_aug = apply_transforms(training_dataset, fraction=0.5, trfs=trfs, verbose=True)\n",
    "# Transpose due to random flip\n",
    "X_aug = np.transpose(X_aug, (0, 2, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28271c1f-dab0-48f4-9a13-e779db633d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf7b93-3e3b-46c6-8509-f1d1b1576ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.transpose(X[10], (1, 2, 0)))\n",
    "plt.title(\"Original Frame\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Augmented Frame\")\n",
    "plt.imshow(np.transpose(X_aug[10], (1, 2, 0)))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71340dbc-ba0a-40a2-856d-d8310132d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc373302-f119-4a72-a230-b25f8c3c256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bdb378-3155-4873-8b51-95d77dacbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, X_aug), 0)\n",
    "y_train = np.concatenate((y_train, y_aug), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e249a-de35-4324-ae7d-6d3a10916afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensor\n",
    "X_train, y_train = torch.Tensor(X_train), torch.Tensor(y_train)\n",
    "X_test, y_test = torch.Tensor(X_test), torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e188fd-6f3f-4e31-9d08-839e7bd02d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_train, y_train), batch_size=32\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_test, y_test), batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d7af7-68b4-4c76-bc19-a91a3069fd39",
   "metadata": {},
   "source": [
    "#### CNN class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32711fc-e6b4-4333-94fc-e91ea1566fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import CNNclassifer\n",
    "from src.training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a2a60-8e83-490c-b85a-725a823bcd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNNclassifer(\n",
    "    in_dim=300,\n",
    "    n_classes=3,\n",
    "    in_channels=3,\n",
    "    n_filters=[32, 16, 16, 8],\n",
    "    n_neurons=[1000, 500, 200],\n",
    "    kernel_size=[(3, 3)] * 4,\n",
    "    pool_size=(2, 2),\n",
    "    dropout=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db9aee-4cd5-430f-aae8-4aed0102da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4975789-64cc-4be1-8fd2-cefe2a8d66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    cnn,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    device=\"auto\",\n",
    "    epochs=100,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb48b77-2c8b-44b8-b8e0-6543d78a1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev = (\n",
    "    (torch.nn.functional.softmax(cnn(X_test.to(\"cuda\")), -1))\n",
    "    .argmax(-1)\n",
    "    .to(\"cpu\")\n",
    "    .detach()\n",
    "    .numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af624f7-d587-4a70-a066-33ba5fe8921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cpu = y_test.to(\"cpu\").detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc5351-b210-4c03-a7d8-a9b74d7342d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_prev, y_test_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501a627-e265-48fa-9707-33c5e0515746",
   "metadata": {},
   "source": [
    "#### Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86461869-bbff-44e4-88d0-e1b5e84e2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f46ab-5a7c-4a38-9e99-1169b8f421aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidationAccuracy(\n",
    "    cnn,\n",
    "    X,\n",
    "    y,\n",
    "    k=10,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    device=\"auto\",\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    verbose=False,\n",
    "):\n",
    "\n",
    "    # Creating data folds\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    cv_acc = []\n",
    "    cv_loss = []\n",
    "    cv_acc_train = []\n",
    "    cv_loss_train = []\n",
    "\n",
    "    pbar = tqdm(kf.split(X)) if verbose else kf.split(X)\n",
    "    fold = 1\n",
    "    for train_index, test_index in pbar:\n",
    "\n",
    "        pbar.set_description(f\"Training in fold {fold}/{k}\")\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        X_train, y_train = torch.Tensor(X_train), torch.Tensor(y_train)\n",
    "        X_test, y_test = torch.Tensor(X_test), torch.Tensor(y_test)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "            torch.utils.data.TensorDataset(X_train, y_train), batch_size=batch_size\n",
    "        )\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "            torch.utils.data.TensorDataset(X_test, y_test), batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        out = train(\n",
    "            cnn,\n",
    "            trainloader,\n",
    "            testloader,\n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            verbose=verbose,\n",
    "            return_scores=True,\n",
    "            return_train_scores=True,\n",
    "        )\n",
    "\n",
    "        cv_loss_train += [out[0]]\n",
    "        cv_acc_train += [out[1]]\n",
    "        cv_loss += [out[2]]\n",
    "        cv_acc += [out[3]]\n",
    "\n",
    "        fold = fold + 1\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        np.stack((cv_loss_train, cv_acc_train, cv_loss, cv_acc), -1),\n",
    "        columns=[\"loss_train\", \"acc_train\", \"loss_test\", \"acc_test\"],\n",
    "    )\n",
    "    df.index.name = \"fold\"\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4ffa8-9fb1-4137-9da7-62b63b3dce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = CrossValidationAccuracy(\n",
    "    cnn, X_train, y_train, k=5, epochs=100, batch_size=32, device=\"auto\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8a0a0-2a8b-4155-a2da-ef4778836fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = acc[\"acc_test\"].median()\n",
    "sigma = acc[\"acc_test\"].std()\n",
    "print(f\"{median:.3f} +- {sigma:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd76f4c-316c-4641-97a6-7fe86d6e61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs and labels\n",
    "X, y = apply_transforms(\n",
    "    training_dataset, fraction=None, trfs=transforms.Resize((300, 300)), verbose=True\n",
    ")\n",
    "# Augment dataset\n",
    "X_aug, y_aug = apply_transforms(training_dataset, fraction=0.5, trfs=trfs, verbose=True)\n",
    "# Transpose due to random flip\n",
    "X_aug = np.transpose(X_aug, (0, 2, 1, 3))\n",
    "\n",
    "X_train = np.concatenate((X_train, X_aug), 0)\n",
    "y_train = np.concatenate((y_train, y_aug), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b17e5-a5af-48e1-a829-6ca905d57abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1_nodrop = CNNclassifer(\n",
    "    in_dim=300,\n",
    "    n_classes=3,\n",
    "    in_channels=3,\n",
    "    n_filters=[32, 16],\n",
    "    n_neurons=[1000, 200],\n",
    "    kernel_size=[(3, 3), (3, 3)],\n",
    "    pool_size=(2, 2),\n",
    "    dropout=0.0,\n",
    ")\n",
    "\n",
    "cnn_1 = CNNclassifer(\n",
    "    in_dim=300,\n",
    "    n_classes=3,\n",
    "    in_channels=3,\n",
    "    n_filters=[32, 16],\n",
    "    n_neurons=[1000, 200],\n",
    "    kernel_size=[(3, 3), (3, 3)],\n",
    "    pool_size=(2, 2),\n",
    "    dropout=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0dd70-93cf-4dc7-9934-6ed424027701",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cnn_1 = CrossValidationAccuracy(\n",
    "    cnn_1, X_train, y_train, k=5, epochs=100, batch_size=32, device=\"auto\", verbose=True\n",
    ")\n",
    "\n",
    "cv_cnn_1_nodrop = CrossValidationAccuracy(\n",
    "    cnn_1_nodrop,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    k=5,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    device=\"auto\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e1b9e-7d58-4b8e-b150-410ebb1c23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_2 = CNNclassifer(\n",
    "    in_dim=300,\n",
    "    n_classes=3,\n",
    "    in_channels=3,\n",
    "    n_filters=[32, 16, 16, 8],\n",
    "    n_neurons=[1000, 500, 500, 200],\n",
    "    kernel_size=[(3, 3)] * 4,\n",
    "    pool_size=(2, 2),\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "cnn_2_nodrop = CNNclassifer(\n",
    "    in_dim=300,\n",
    "    n_classes=3,\n",
    "    in_channels=3,\n",
    "    n_filters=[32, 16, 16, 8],\n",
    "    n_neurons=[1000, 500, 500, 200],\n",
    "    kernel_size=[(3, 3)] * 4,\n",
    "    pool_size=(2, 2),\n",
    "    dropout=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0008f19-0ecb-42e1-af11-2520f21a277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cnn_2 = CrossValidationAccuracy(\n",
    "    cnn_2, X_train, y_train, k=5, epochs=100, batch_size=32, device=\"auto\", verbose=True\n",
    ")\n",
    "\n",
    "cv_cnn_2_nodrop = CrossValidationAccuracy(\n",
    "    cnn_2_nodrop,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    k=5,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    device=\"auto\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8355b67-7d0e-4c42-8093-a4176ab98756",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fe977-534e-4b83-971e-0a8b4baa2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354a5ca-4222-44da-894f-f96636c0ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cnn_1[\"model\"] = \"cnn1\"\n",
    "cv_cnn_1[\"drop\"] = 1\n",
    "cv_cnn_1_nodrop[\"model\"] = \"cnn1_nodrop\"\n",
    "cv_cnn_1_nodrop[\"drop\"] = 0\n",
    "cv_cnn_2[\"model\"] = \"cnn2\"\n",
    "cv_cnn_2[\"drop\"] = 1\n",
    "cv_cnn_2_nodrop[\"model\"] = \"cnn2_nodrop\"\n",
    "cv_cnn_2_nodrop[\"drop\"] = 0\n",
    "cv_scores = pd.concat([cv_cnn_1, cv_cnn_1_nodrop, cv_cnn_2, cv_cnn_2_nodrop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6373d23-0c02-4c6b-a9d6-4f1619d95a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c9dc0-f654-4889-bebe-d4d47aad4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edff1cd-5d3a-4f10-a5ac-f0b6f82622d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pvalue_to_asterisks(pvalue):\n",
    "    if pvalue <= 0.0001:\n",
    "        return \"****\"\n",
    "    elif pvalue <= 0.001:\n",
    "        return \"***\"\n",
    "    elif pvalue <= 0.01:\n",
    "        return \"**\"\n",
    "    elif pvalue <= 0.05:\n",
    "        return \"*\"\n",
    "    return \"ns\"\n",
    "\n",
    "\n",
    "def add_stats_annot(pval, x1, x2, y, h, col):\n",
    "    plt.plot([x1, x1, x2, x2], [y, y + h, y + h, y], lw=1.5, c=col)\n",
    "    plt.text(\n",
    "        (x1 + x2) * 0.5,\n",
    "        y + h,\n",
    "        convert_pvalue_to_asterisks(pval),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        color=col,\n",
    "    )\n",
    "\n",
    "\n",
    "def mwhitney(x, y, boot=1000):\n",
    "    _, p = mannwhitneyu(\n",
    "        np.random.choice(x, size=boot),\n",
    "        np.random.choice(y, size=boot),\n",
    "        alternative=\"greater\",\n",
    "    )\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecd78c-b28e-45bf-89f4-5c3963f7e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "sns.boxplot(data=cv_scores, x=\"model\", y=\"acc_test\", hue=\"drop\", showfliers=False)\n",
    "sns.boxplot(\n",
    "    data=cv_scores,\n",
    "    x=\"model\",\n",
    "    y=\"acc_train\",\n",
    "    hue=\"drop\",\n",
    "    showfliers=False,\n",
    "    color=\"lightgray\",\n",
    ")\n",
    "\n",
    "add_stats_annot(\n",
    "    mwhitney(\n",
    "        cv_scores.loc[cv_scores.model == \"cnn1_nodrop\"].acc_test,\n",
    "        cv_scores.loc[cv_scores.model == \"cnn1\"].acc_test,\n",
    "    ),\n",
    "    0.2,\n",
    "    0.8,\n",
    "    0.9,\n",
    "    0.005,\n",
    "    \"k\",\n",
    ")\n",
    "\n",
    "add_stats_annot(\n",
    "    mwhitney(\n",
    "        cv_scores.loc[cv_scores.model == \"cnn2\"].acc_test,\n",
    "        cv_scores.loc[cv_scores.model == \"cnn2_nodrop\"].acc_test,\n",
    "    ),\n",
    "    2.2,\n",
    "    2.8,\n",
    "    0.97,\n",
    "    0.005,\n",
    "    \"k\",\n",
    ")\n",
    "\n",
    "add_stats_annot(\n",
    "    mwhitney(\n",
    "        cv_scores.loc[cv_scores.model == \"cnn2\"].acc_test,\n",
    "        cv_scores.loc[cv_scores.model == \"cnn1\"].acc_test,\n",
    "    ),\n",
    "    0.2,\n",
    "    2.2,\n",
    "    0.96,\n",
    "    0.005,\n",
    "    \"k\",\n",
    ")\n",
    "\n",
    "ax.legend().remove()\n",
    "[ax.spines[pos].set_visible(False) for pos in [\"top\", \"right\"]]\n",
    "\n",
    "\n",
    "plt.xticks(\n",
    "    [0.2, 0.8, 2.2, 2.8],\n",
    "    [\"CNN1\", \"CNN1 (no drop.)\", \"CNN2\", \"CNN2 (no drop.)\"],\n",
    "    rotation=45,\n",
    ")\n",
    "plt.ylabel(\"CV accuracies\")\n",
    "plt.xlabel(\"\")\n",
    "plt.savefig(\"figures/cv_acc.png\", bbox_inches=\"tight\", transparent=True, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de9c72-7c79-4465-9753-b02e443b34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_2, \"cnn_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf26440-804e-4b9d-b539-ce024426a7dd",
   "metadata": {},
   "source": [
    "#### Classify video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ef4cf-30da-4faf-a922-8ab944a46b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from src.utils import apply_transforms\n",
    "from src.video_processing import extract_video_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77c1bd-1c96-489a-894a-4739da9e1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_video = \"/home/projeto_mimi/videos/video2B.avi\"\n",
    "\n",
    "frames = extract_video_frames(path_to_video)\n",
    "\n",
    "_, H, W, d = frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f58831-8184-4ec6-9217-96b36ea10ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = xr.DataArray(frames, dims=(\"frames\", \"W\", \"H\", \"d\")).isel(\n",
    "    frames=slice(4000, 6000)\n",
    ")\n",
    "\n",
    "n_frames = len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254653e-0064-4f56-ac23-080c3db3386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, _ = apply_transforms(\n",
    "    frames, fraction=None, trfs=transforms.Resize((300, 300)), verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5bca5-735d-4515-b5f4-4df1aa1c38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = torch.Tensor(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a310e6-b20d-447c-ac7d-db41245aff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"cnn_2\")\n",
    "model.eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b883ec-9437-4404-b92a-b3d0d8ac2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.empty(n_frames)\n",
    "for i in tqdm(range(n_frames)):\n",
    "    out = model(frames[i, ...][None, ...].to(\"cuda\"))\n",
    "    labels[i] = torch.nn.functional.softmax(out.to(\"cpu\"), dim=-1).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328071ff-1922-44c2-8ab8-baa86844c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506b264-6403-42d9-8bad-4cbed32b9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.to(\"cpu\").detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475a2f1-8413-487c-aa88-b0751cddc020",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_frames):\n",
    "    img = np.transpose(frames[i], (1, 2, 0))\n",
    "    if labels[i] == 1:\n",
    "        frame = cv2.copyMakeBorder(\n",
    "            img, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value=[255, 0, 0]\n",
    "        )\n",
    "    elif labels[i] == 2:\n",
    "        frame = cv2.copyMakeBorder(\n",
    "            img, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value=[0, 255, 0]\n",
    "        )\n",
    "    elif labels[i] == 0:\n",
    "        frame = cv2.copyMakeBorder(\n",
    "            img, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value=[0, 0, 255]\n",
    "        )\n",
    "    cv2.imwrite(f\"labeled_frames/frame_{labels[i]}_{i}.jpg\", frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
